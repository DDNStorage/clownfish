# Copyright (c) 2018 DataDirect Networks, Inc.
# All Rights Reserved.
# Author: lixi@ddn.com
"""
Console that manages the scheduler
"""
# pylint: disable=too-many-lines
import xmlrpclib
import getopt
import sys
import os
import time
import traceback
import yaml

# local libs
from pylustre import clog
from pylustre import utils
from pylustre import time_util
from pylustre import cstr
from pylustre import ssh_host
from pylustre import lyaml
from pylustre import lvirt
from pylustre import lustre
from pylustre import constants
from pyltest import ltest_scheduler


LTEST_LAUNCH_LOG_DIR = "/var/log/ltest_launch"
CHECK_TIME = time_util.utcnow()
EXIT_REASON = "unkown reason"
SHUTTING_DOWN = False
DEFAULT_HOST_TIMEOUT = 1800
HOST_ALLOCATION_INTERVAL = 3
DEFAULT_LUSTRE_RPM_DIR = "/lustre_rpms"
DEFAULT_E2FSPROGS_RPM_DIR = "/e2fsprogs_rpms"
DEV_MAPPER_PREFIX = "/dev/mapper/"
CLOWNFISH_ISO_PATTERN = "clownfish-*.x86_64.iso"
CLOWNFISH_MD5_PATTERN = "clownfish-*.x86_64.md5"


def usage():
    """
    Print the usage of the command
    """
    command = sys.argv[0]
    utils.eprint("Usage: %s [--lustre|-l <lustre_dir>] [--e2fsprogs|-e <e2fsprogs_dir>]\n"
                 "          [--server|-s <server>] [--source_path|-p <source_path>]\n"
                 "          [--host_timeout <host_timeout>]\n"
                 "\n"
                 "lustre_dir:\n"
                 "    The dir of Lustre RPMs, usually generated by lbuild.\n"
                 "    By default '%s'\n"
                 "e2fsprogs_dir:\n"
                 "    The dir of E2fsprogs RPMs.\n"
                 "    By default '%s'.\n"
                 "server:\n"
                 "    The server address.\n"
                 "    By default localhost.\n"
                 "source_path:\n"
                 "    The path to Clownfish source code.\n"
                 "    By default current directory.\n"
                 "host_timeout:\n"
                 "    The seconds to wait for host allocation.\n"
                 "    By default %d seconds. 0 means wait for ever.\n"
                 "\n"
                 "examples:\n"
                 "%s\n"
                 "%s -s localhost\n"
                 "%s -s http://localhost -p /dir/to/clownfish.git\n"
                 "%s -s http://localhost:1234 -p /dir/to/clownfish.git\n"
                 "%s -s http://10.0.0.10:1234 -p /dir/to/clownfish.git\n"
                 "%s -l /dir/to/lustre_rpms -e /dir/to/e2fsprogs_rpms -s http://10.0.0.10:1234 -p /dir/to/clownfish.git"
                 % (command, DEFAULT_LUSTRE_RPM_DIR, DEFAULT_E2FSPROGS_RPM_DIR,
                    DEFAULT_HOST_TIMEOUT, command, command, command,
                    command, command, command))


class LaunchArg(object):
    """
    The arg of launch command
    """
    # pylint: disable=too-few-public-methods,too-many-instance-attributes
    def __init__(self):
        self.la_server = "http://localhost:1234"
        self.la_source_path = os.getcwd()
        self.la_host_wait_time = DEFAULT_HOST_TIMEOUT
        self.la_lustre_dir = DEFAULT_LUSTRE_RPM_DIR
        self.la_e2fsprogs_dir = DEFAULT_E2FSPROGS_RPM_DIR
        # Init when building
        self.la_test_host_source_path = None
        self.la_test_host_iso_fpath = None
        self.la_test_host_iso_dir = None
        self.la_test_host_md5_fpath = None

    def la_update_server(self, log, server):
        """
        Update the server URL
        """
        if not server.startswith("http://"):
            server = "http://" + server
        if server.count(":") != 2:
            server = server + ":" + str(ltest_scheduler.TEST_SCHEDULER_PORT)
        self.la_server = server
        log.cl_debug("updated the url to [%s]", server)
        return 0

    def la_update_source_path(self, log, path):
        """
        Update the source path
        """
        if not os.path.isdir(path):
            log.cl_error("source directory [%s] is not a directory", path)
            return -1

        self.la_source_path = path
        log.cl_debug("updated the source path to [%s]", path)
        return 0

    def la_update_host_wait_time(self, log, second):
        """
        Update the host wait time
        """
        self.la_host_wait_time = second
        log.cl_debug("the host wait time is [%d]", self.la_host_wait_time)
        return 0

    def la_update_lustre_dir(self, log, lustre_dir):
        """
        Update the dir of Lustre RPMs
        """
        if not os.path.isdir(lustre_dir):
            log.cl_error("Lustre RPMs directory [%s] is not a directory",
                         lustre_dir)
            return -1
        self.la_lustre_dir = lustre_dir
        log.cl_debug("updated the lustre_dir to [%s]", lustre_dir)
        return 0

    def la_update_e2fsprogs_dir(self, log, e2fsprogs_dir):
        """
        Update the dir of E2fsprogs RPMs
        """
        if not os.path.isdir(e2fsprogs_dir):
            log.cl_error("E2fsprogs RPMs directory [%s] is not a directory",
                         e2fsprogs_dir)
            return -1
        self.la_e2fsprogs_dir = e2fsprogs_dir
        log.cl_debug("updated the url to [%s]", e2fsprogs_dir)
        return 0

    def la_check_arguments(self, log):
        """
        Check whether all arguments are valid
        """
        ret = self.la_update_server(log, self.la_server)
        if ret:
            return ret

        ret = self.la_update_host_wait_time(log, self.la_host_wait_time)
        if ret:
            return ret

        ret = self.la_update_source_path(log, self.la_source_path)
        if ret:
            return ret

        ret = self.la_update_lustre_dir(log, self.la_lustre_dir)
        if ret:
            return ret

        ret = self.la_update_lustre_dir(log, self.la_lustre_dir)
        if ret:
            return ret

        ret = self.la_update_e2fsprogs_dir(log, self.la_e2fsprogs_dir)
        if ret:
            return ret

        return 0


class ClientRPCHost(ltest_scheduler.RPCHost):
    """
    The host for transfering between scheduler and its clients
    """
    # pylint: disable=too-few-public-methods
    def __init__(self, hostname,
                 global_template_hostname=None,
                 kvm_template_config=None,
                 kvm_server_hostname=None,
                 expected_distro=None, ipv4_addresses=None,
                 kvm_template_ipv4_address=None):
        # pylint: disable=too-many-arguments
        super(ClientRPCHost, self).__init__(hostname,
                                            kvm_server_hostname=kvm_server_hostname,
                                            expected_distro=expected_distro,
                                            ipv4_addresses=ipv4_addresses,
                                            kvm_template_ipv4_address=kvm_template_ipv4_address)
        self.crh_host = ssh_host.SSHHost(hostname)
        self.crh_global_template_hostname = global_template_hostname
        self.crh_kvm_template_config = kvm_template_config
        self.crh_shared_disk_ids = []

    def crh_add_shared_disk(self, disk_id):
        """
        Add the shared disk ID
        """
        self.crh_shared_disk_ids.append(disk_id)


def send_clownfish_source(log, workspace, build_host, launch_argument):
    """
    Send the Clownfish source codes to remote host
    """
    source_path = launch_argument.la_source_path
    log.cl_info("sending the source code in directory [%s] of local host to "
                "directory [%s] on host [%s]", source_path, workspace,
                build_host.sh_hostname)
    ret = build_host.sh_send_file(log, source_path, workspace)
    if ret:
        log.cl_error("failed to send directory [%s] on local host to "
                     "directory [%s] on host [%s]",
                     source_path, workspace, build_host.sh_hostname)
        return -1
    log.cl_info("sent directory [%s] on local host to "
                "directory [%s] on host [%s]",
                source_path, workspace, build_host.sh_hostname)
    basename = os.path.basename(source_path)

    remote_source_path = workspace + "/" + constants.CLOWNFISH_BUILD_LOG_DIR_BASENAME
    origin_remote_source_path = workspace + "/" + basename
    if origin_remote_source_path != remote_source_path:
        command = ("mv %s %s" %
                   (origin_remote_source_path, remote_source_path))
        retval = build_host.sh_run(log, command)
        if retval.cr_exit_status != 0:
            log.cl_error("failed to run command [%s] on host [%s], "
                         "ret = [%d], stdout = [%s], stderr = [%s]",
                         command, build_host.sh_hostname,
                         retval.cr_exit_status, retval.cr_stdout,
                         retval.cr_stderr)
            log.cl_error("please clean up the dir [%s] on host [%s] "
                         "manually to avoid exhaustion of disk space on that "
                         "host", origin_remote_source_path,
                         build_host.sh_hostname)
            return -1

    launch_argument.la_test_host_source_path = remote_source_path
    launch_argument.la_test_host_iso_dir = remote_source_path + "/ISO"
    return 0


def ssh_hosts_add(log, ssh_host_dict, ssh_host_configs, rpc_host):
    """
    Add the server of rpc_host to ssh_host_dict
    """
    kvm_server_hostname = rpc_host.lrh_kvm_server_hostname
    if kvm_server_hostname not in ssh_host_dict:
        ssh_host_dict[kvm_server_hostname] = True
        ssh_host_config = {}
        ssh_host_config[cstr.CSTR_HOST_ID] = kvm_server_hostname
        ssh_host_config[cstr.CSTR_HOSTNAME] = kvm_server_hostname
        ssh_host_configs.append(ssh_host_config)
        log.cl_debug("adding KVM server [%s] to config",
                     kvm_server_hostname)


def generate_lvirt_config_ssh_hosts(log, hosts, pairs, config):
    """
    Generate the ssh_hosts part of the lvirt config
    """
    ssh_host_configs = []
    ssh_host_dict = {}

    for rpc_hosts in pairs:
        rpc_host = rpc_hosts[0]
        ssh_hosts_add(log, ssh_host_dict, ssh_host_configs, rpc_host)

    for rpc_host in hosts:
        ssh_hosts_add(log, ssh_host_dict, ssh_host_configs, rpc_host)

    config[cstr.CSTR_SSH_HOSTS] = ssh_host_configs


def generate_lvirt_config_templates(log, kvm_server_dict, config):
    """
    Generate the templates part of the lvirt config
    """
    template_configs = []

    # kvm_server_dict has keys of server hostnames, and values of
    # diction. The diction has keys of global template hostname,
    # and values of full template config
    for diction in kvm_server_dict.values():
        for global_template_hostname, template_config in diction.iteritems():
            template_configs.append(template_config)
            log.cl_debug("adding template host [%s] to config",
                         global_template_hostname)

    config[cstr.CSTR_TEMPLATES] = template_configs


def vm_hosts_add(log, vm_host_configs, rpc_host):
    """
    Add the rpc_host to vm_host_configs
    """
    vm_host_config = {}
    vm_host_config[cstr.CSTR_HOSTNAME] = rpc_host.lrh_hostname
    vm_host_config[cstr.CSTR_REINSTALL] = False
    vm_host_config[cstr.CSTR_TEMPLATE_HOSTNAME] = rpc_host.crh_global_template_hostname
    vm_host_config[cstr.CSTR_SHARED_DISK_IDS] = rpc_host.crh_shared_disk_ids
    vm_host_config[cstr.CSTR_IPS] = rpc_host.lrh_ipv4_addresses
    vm_host_configs.append(vm_host_config)
    log.cl_debug("adding VM host [%s] to config", rpc_host.lrh_hostname)


def generate_lvirt_config_vm_hosts(log, hosts, pairs, config):
    """
    Generate the vm_hosts part of the lvirt config
    """
    vm_host_configs = []

    for rpc_hosts in pairs:
        for rpc_host in rpc_hosts:
            vm_hosts_add(log, vm_host_configs, rpc_host)

    for rpc_host in hosts:
        vm_hosts_add(log, vm_host_configs, rpc_host)

    config[cstr.CSTR_VM_HOSTS] = vm_host_configs


def generate_lvirt_config_shared_disks(shared_disk_dict, config):
    """
    Generate the shared_disks part of the lvirt config
    """
    config[cstr.CSTR_SHARED_DISKS] = shared_disk_dict.values()


def config_shared_disk_add(log, shared_disk_dict, disk_id, size,
                           image_fpath, server_host_id):
    """
    Add shared disk to the dict
    """
    # pylint: disable=too-many-arguments
    if disk_id in shared_disk_dict:
        log.cl_error("disk ID [%s] already exists", disk_id)
        return -1
    shared_disk_config = {}
    shared_disk_config[cstr.CSTR_DISK_ID] = disk_id
    shared_disk_config[cstr.CSTR_SIZE] = size
    shared_disk_config[cstr.CSTR_SERVER_HOST_ID] = server_host_id
    shared_disk_config[cstr.CSTR_IMAGE_FILE] = image_fpath
    shared_disk_dict[disk_id] = shared_disk_config
    return 0


def add_shared_device(log, pair, shared_disk_dict, disk_id, size):
    """
    Save the shared disk IDs into the ClientRPCHost
    """
    host0 = pair[0]
    template_config = host0.crh_kvm_template_config
    # Image dir might be different for the templates of two hosts,
    # use the first one's
    image_dir = template_config[cstr.CSTR_IMAGE_DIR]
    # Host ID should be the same for two hosts
    image_fname = (host0.lrh_hostname + "_shared_" +
                   str(len(host0.crh_shared_disk_ids)) + ".img")
    image_fpath = os.path.join(image_dir, image_fname)
    server_host_id = template_config[cstr.CSTR_SERVER_HOST_ID]

    ret = config_shared_disk_add(log, shared_disk_dict, disk_id, size,
                                 image_fpath, server_host_id)
    if ret:
        log.cl_error("failed to add shared disk with ID [%s]", disk_id)
        return -1

    for host in pair:
        host.crh_add_shared_disk(disk_id)
    return 0


class TestCluster(object):
    """
    The cluster to run test

    Host 0: Clownfish install server, Lustre client
    Host 1: Clownfish server 0
    Host 2: Clownfish server 1
    Host 3: Lustre client

    Pair 0: MGS/lustre0-MDS, devices: mgs(1GB), mdt0(5GB), mdt1(5GB)
    Pair 1: lustre0-OSS, devices: ost0(5GB), ost1(5GB), ost2(5GB)
    Pair 2: llustre1-MDS/OSS, devices: mdt0(5GB), ost0(5GB), ost1(5GB)
    """
    # pylint: disable=too-few-public-methods,too-many-instance-attributes
    PAIR_NUMBER = 3
    HOST_NUMBER = 4

    def __init__(self, workspace, test_host, hosts, pairs, rpc_ip_address,
                 kvm_server_dict):
        # pylint: disable=too-many-arguments,too-many-statements
        self.tc_vm_hosts = []
        self.tc_vm_hosts += hosts
        for pair in pairs:
            self.tc_vm_hosts += pair
        self.tc_clownfish_test_logdir = (workspace + "/" +
                                         constants.CLOWNFISH_TEST_LOG_DIR_BASENAME)
        self.tc_rpc_ip_address = rpc_ip_address
        self.tc_kvm_server_dict = kvm_server_dict
        self.tc_workspace = workspace
        self.tc_cluster_id = utils.random_word(7)
        self.tc_hosts = hosts
        self.tc_client_host0 = hosts[0]
        self.tc_client_host1 = hosts[3]
        self.tc_test_host = test_host
        self.tc_install_server = self.tc_hosts[0]
        self.tc_clownfish_server0 = self.tc_hosts[1]
        self.tc_clownfish_server1 = self.tc_hosts[2]
        self.tc_pairs = pairs
        self.tc_mgs_pair = pairs[0]
        self.tc_mgt_size = 1
        self.tc_mdt_size = 5
        self.tc_ost_size = 5
        self.tc_mgt_disk_id = self.tc_cluster_id + "_mgt"
        self.tc_fs0_fsname = self.tc_cluster_id + "0"
        self.tc_fs0_mnt = "/mnt/" + self.tc_fs0_fsname
        self.tc_fs0_mdt_disk_id_prefix = (self.tc_fs0_fsname + "_" +
                                          "mdt")
        self.tc_fs0_ost_disk_id_prefix = (self.tc_fs0_fsname + "_" +
                                          "ost")
        self.tc_fs0_mdt_number_per_mds = 2
        self.tc_fs0_ost_number_per_oss = 3
        self.tc_fs0_mds_pair0 = pairs[0]
        self.tc_fs0_oss_pair0 = pairs[1]

        self.tc_fs1_fsname = self.tc_cluster_id + "1"
        self.tc_fs1_mnt = "/mnt/" + self.tc_fs1_fsname
        self.tc_fs1_mdt_disk_id_prefix = (self.tc_fs1_fsname + "_" +
                                          "mdt")
        self.tc_fs1_ost_disk_id_prefix = (self.tc_fs1_fsname + "_" +
                                          "ost")
        self.tc_fs1_mdt_number_per_mds = 1
        self.tc_fs1_ost_number_per_oss = 2
        self.tc_fs1_mds_pair0 = pairs[2]
        self.tc_fs1_oss_pair0 = pairs[2]
        fname = lvirt.LVIRT_CONFIG_FNAME
        self.tc_lvirt_config_fpath = workspace + "/" + fname
        fname = constants.CLOWNFISH_CONFIG_FNAME
        self.tc_clownfish_config_fpath = workspace + "/" + fname
        fname = constants.CLOWNFISH_INSTALL_CONFIG_FNAME
        self.tc_clownfish_install_config_fpath = workspace + "/" + fname
        fname = constants.CLOWNFISH_TEST_CONFIG_FNAME
        self.tc_clownfish_test_config_fpath = workspace + "/" + fname
        fname = constants.CLOWNFISH_BUILD_CONFIG_FNAME
        self.tc_clownfish_build_config_fpath = workspace + "/" + fname
        self.tc_test_host_lustre_rpm_dir = workspace + DEFAULT_LUSTRE_RPM_DIR
        self.tc_test_host_e2fsprogs_rpm_dir = workspace + DEFAULT_E2FSPROGS_RPM_DIR

    def _tc_add_shared_mgt(self, log, shared_disk_dict):
        """
        Save the shared disk MGS into the ClientRPCHost
        """
        return add_shared_device(log, self.tc_mgs_pair, shared_disk_dict,
                                 self.tc_mgt_disk_id,
                                 self.tc_mgt_size)

    def _tc_fs0_add_shared_devices(self, log, shared_disk_dict):
        """
        Save the shared disks of file system 0
        """
        for mdt_index in range(self.tc_fs0_mdt_number_per_mds):
            mdt_disk_id = self.tc_fs0_mdt_disk_id_prefix + str(mdt_index)
            ret = add_shared_device(log, self.tc_fs0_mds_pair0,
                                    shared_disk_dict,
                                    mdt_disk_id,
                                    self.tc_mdt_size)
            if ret:
                log.cl_error("failed to add shared disk for [%s]", mdt_disk_id)
                return -1

        for ost_index in range(self.tc_fs0_ost_number_per_oss):
            ost_disk_id = self.tc_fs0_ost_disk_id_prefix + str(ost_index)
            ret = add_shared_device(log, self.tc_fs0_oss_pair0,
                                    shared_disk_dict,
                                    ost_disk_id,
                                    self.tc_ost_size)
            if ret:
                log.cl_error("failed to add shared disk for [%s]", ost_disk_id)
                return -1
        return 0

    def _tc_fs1_add_shared_devices(self, log, shared_disk_dict):
        """
        Save the shared disks of file system 1
        """
        for mdt_index in range(self.tc_fs1_mdt_number_per_mds):
            mdt_disk_id = self.tc_fs1_mdt_disk_id_prefix + str(mdt_index)
            ret = add_shared_device(log, self.tc_fs1_mds_pair0,
                                    shared_disk_dict,
                                    mdt_disk_id,
                                    self.tc_mdt_size)
            if ret:
                log.cl_error("failed to add shared disk for [%s]", mdt_disk_id)
                return -1

        for ost_index in range(self.tc_fs1_ost_number_per_oss):
            ost_disk_id = self.tc_fs1_ost_disk_id_prefix + str(ost_index)
            ret = add_shared_device(log, self.tc_fs1_oss_pair0,
                                    shared_disk_dict,
                                    ost_disk_id,
                                    self.tc_ost_size)
            if ret:
                log.cl_error("failed to add shared disk for [%s]", ost_disk_id)
                return -1
        return 0

    def tc_add_shared_devices(self, log, shared_disk_dict):
        """
        Save the shared disks into the ClientRPCHost
        """
        ret = self._tc_add_shared_mgt(log, shared_disk_dict)
        if ret:
            return -1

        ret = self._tc_fs0_add_shared_devices(log, shared_disk_dict)
        if ret:
            return -1

        ret = self._tc_fs1_add_shared_devices(log, shared_disk_dict)
        if ret:
            return -1

        return 0

    def tc_send_lustre_e2fsprogs_rpms(self, log, launch_argument):
        """
        Send Lustre RPMs and E2fsprogs RPMs
        """
        host = self.tc_test_host.crh_host
        workspace = self.tc_workspace

        local_rpm_dir = launch_argument.la_lustre_dir
        test_host = self.tc_test_host.crh_host
        ret = test_host.sh_send_file(log, local_rpm_dir, workspace)
        if ret:
            log.cl_error("failed to send dir [%s] on local host to "
                         "directory [%s] on host [%s]",
                         local_rpm_dir, workspace, test_host.sh_hostname)
            return -1
        basename = os.path.basename(local_rpm_dir)
        remote_rpm_dir = workspace + "/" + basename
        remote_lustre_rpm_dir = self.tc_test_host_lustre_rpm_dir
        if remote_rpm_dir != remote_lustre_rpm_dir:
            command = ("mv %s %s" % (remote_rpm_dir, remote_lustre_rpm_dir))
            retval = host.sh_run(log, command)
            if retval.cr_exit_status != 0:
                log.cl_error("failed to run command [%s] on host [%s], "
                             "ret = [%d], stdout = [%s], stderr = [%s]",
                             command, host.sh_hostname,
                             retval.cr_exit_status, retval.cr_stdout,
                             retval.cr_stderr)
                return -1

        local_rpm_dir = launch_argument.la_e2fsprogs_dir
        test_host = self.tc_test_host.crh_host
        ret = test_host.sh_send_file(log, local_rpm_dir, workspace)
        if ret:
            log.cl_error("failed to send dir [%s] on local host to "
                         "directory [%s] on host [%s]",
                         local_rpm_dir, workspace, test_host.sh_hostname)
            return -1
        basename = os.path.basename(local_rpm_dir)
        remote_rpm_dir = workspace + "/" + basename
        remote_e2fsprogs_rpm_dir = self.tc_test_host_e2fsprogs_rpm_dir
        if remote_rpm_dir != remote_e2fsprogs_rpm_dir:
            command = ("mv %s %s" % (remote_rpm_dir, remote_e2fsprogs_rpm_dir))
            retval = host.sh_run(log, command)
            if retval.cr_exit_status != 0:
                log.cl_error("failed to run command [%s] on host [%s], "
                             "ret = [%d], stdout = [%s], stderr = [%s]",
                             command, host.sh_hostname,
                             retval.cr_exit_status, retval.cr_stdout,
                             retval.cr_stderr)
                return -1

    def tc_get_and_clean_dir(self, log, host, logdir):
        """
        Get and clean log
        """
        host_local_dir = self.tc_workspace + "/" + host.sh_hostname
        ret = utils.mkdir(host_local_dir)
        if ret:
            log.cl_error("failed to create directory [%s] on local host",
                         host_local_dir)
            log.cl_error("please backup the log [%s] on host "
                         "[%s] manually for debug purpose",
                         logdir, host.sh_hostname)
            return -1

        ret = host.sh_get_and_clean_dir(log, logdir, host_local_dir)
        if ret:
            log.cl_error("failed to get and clean dir [%s] on host [%s]",
                         logdir, host.sh_hostname)
        return ret

    def tc_run_clownfish_test(self, log, launch_argument):
        """
        Run clownfish test
        """
        return_value = 0
        workspace = self.tc_workspace
        host = self.tc_test_host.crh_host

        source_path = launch_argument.la_test_host_source_path
        command = ("cd %s && ./clownfish_test --logdir %s --config %s" %
                   (source_path, self.tc_clownfish_test_logdir,
                    self.tc_clownfish_test_config_fpath))
        stdout_file = workspace + "/" + "clownfish_test_watching.stdout"
        stderr_file = workspace + "/" + "clownfish_test_watching.stderr"
        retval = host.sh_watched_run(log, command, stdout_file, stderr_file)
        if retval.cr_exit_status != 0:
            log.cl_error("failed to run command [%s] on host [%s], "
                         "ret = [%d], stdout = [%s], stderr = [%s]",
                         command, host.sh_hostname,
                         retval.cr_exit_status, retval.cr_stdout,
                         retval.cr_stderr)
            return_value = -1

        ret = self.tc_get_and_clean_dir(log, host,
                                        self.tc_clownfish_test_logdir)
        if ret:
            log.cl_error("failed to get and clean dir [%s] on host [%s]",
                         self.tc_clownfish_test_logdir, host.sh_hostname)
            if return_value:
                log.cl_error("please check [%s] on host [%s] and [%s] on "
                             "local host to debug why test of clownfish "
                             "failed", self.tc_clownfish_test_logdir,
                             host.sh_hostname, workspace)
            else:
                log.cl_error("please check why copying remove directory "
                             "failed after success of clownfish test")
            return_value = -1
        return return_value

    def _tc_generate_clownfish_config_lustre_distributions(self, config):
        """
        Generate the lustre distributions part of clownfish.conf
        """
        lustre_distr_configs = []
        lustre_distr_config = {}
        lustre_distr_config[cstr.CSTR_LUSTRE_DISTRIBUTION_ID] = self.tc_cluster_id
        lustre_distr_config[cstr.CSTR_LUSTRE_RPM_DIR] = self.tc_test_host_lustre_rpm_dir
        lustre_distr_config[cstr.CSTR_E2FSPROGS_RPM_DIR] = self.tc_test_host_e2fsprogs_rpm_dir
        lustre_distr_configs.append(lustre_distr_config)
        config[cstr.CSTR_LUSTRE_DISTRIBUTIONS] = lustre_distr_configs

    def _tc_generate_clownfish_config_ssh_hosts(self, config):
        """
        Generate the ssh_hosts part of clownfish.conf
        """
        ssh_host_configs = []
        for pair in self.tc_pairs:
            for rpc_host in pair:
                ssh_host_config = {}
                ssh_host_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
                ssh_host_config[cstr.CSTR_HOSTNAME] = rpc_host.lrh_hostname
                ssh_host_config[cstr.CSTR_LUSTRE_DISTRIBUTION_ID] = self.tc_cluster_id
                ssh_host_configs.append(ssh_host_config)

        for rpc_host in [self.tc_client_host0, self.tc_client_host1]:
            ssh_host_config = {}
            ssh_host_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
            ssh_host_config[cstr.CSTR_HOSTNAME] = rpc_host.lrh_hostname
            ssh_host_config[cstr.CSTR_LUSTRE_DISTRIBUTION_ID] = self.tc_cluster_id
            ssh_host_configs.append(ssh_host_config)
        config[cstr.CSTR_SSH_HOSTS] = ssh_host_configs

    def _tc_generate_clownfish_config_mgs_list(self, config):
        """
        Generate the mgs_list part of clownfish.conf
        """
        mgs_configs = []
        mgs_config = {}
        mgs_config[cstr.CSTR_MGS_ID] = self.tc_cluster_id
        mgs_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_LDISKFS
        mgs_instance_configs = []
        for rpc_host in self.tc_mgs_pair:
            mgs_instance_config = {}
            mgs_instance_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
            mgs_instance_config[cstr.CSTR_DEVICE] = DEV_MAPPER_PREFIX + self.tc_mgt_disk_id
            mgs_instance_config[cstr.CSTR_NID] = rpc_host.lrh_ipv4_addresses[0] + "@tcp"
            mgs_instance_configs.append(mgs_instance_config)
        mgs_config[cstr.CSTR_INSTANCES] = mgs_instance_configs
        mgs_configs.append(mgs_config)
        config[cstr.CSTR_MGS_LIST] = mgs_configs

    def _tc_generate_clownfish_config_fs0_mdts(self, lustre_config):
        """
        Generate the mdts part of lustre 0 of clownfish.conf
        """
        mdt_configs = []
        for mdt_index in range(self.tc_fs0_mdt_number_per_mds):
            mdt_config = {}
            mdt_config[cstr.CSTR_IS_MGS] = False
            mdt_config[cstr.CSTR_INDEX] = mdt_index
            if mdt_index == self.tc_fs0_mdt_number_per_mds - 1:
                is_ldiskfs = False
            else:
                is_ldiskfs = True
            if is_ldiskfs:
                mdt_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_LDISKFS
            else:
                mdt_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_ZFS
            mdt_instance_configs = []
            for rpc_host in self.tc_fs0_mds_pair0:
                mdt_instance_config = {}
                mdt_instance_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
                disk_id = self.tc_fs0_mdt_disk_id_prefix + str(mdt_index)
                block_device = DEV_MAPPER_PREFIX + disk_id
                if is_ldiskfs:
                    device = block_device
                else:
                    zpool = disk_id
                    device = zpool + ("/mdt%d" % mdt_index)
                mdt_instance_config[cstr.CSTR_DEVICE] = device
                mdt_instance_config[cstr.CSTR_NID] = rpc_host.lrh_ipv4_addresses[0] + "@tcp"
                mdt_instance_configs.append(mdt_instance_config)
                if not is_ldiskfs:
                    zpool_create = ("zpool create -f %s %s" %
                                    (zpool, block_device))
                    mdt_instance_config[cstr.CSTR_ZPOOL_CREATE] = zpool_create
            mdt_config[cstr.CSTR_INSTANCES] = mdt_instance_configs
            mdt_configs.append(mdt_config)
        lustre_config[cstr.CSTR_MDTS] = mdt_configs

    def _tc_generate_clownfish_config_fs0_osts(self, lustre_config):
        """
        Generate the osts part of lustre 0 of clownfish.conf
        """
        ost_configs = []
        for ost_index in range(self.tc_fs0_ost_number_per_oss):
            ost_config = {}
            ost_config[cstr.CSTR_IS_MGS] = False
            ost_config[cstr.CSTR_INDEX] = ost_index
            if ost_index == self.tc_fs0_mdt_number_per_mds - 1:
                is_ldiskfs = False
            else:
                is_ldiskfs = True
            if is_ldiskfs:
                ost_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_LDISKFS
            else:
                ost_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_ZFS
            ost_instance_configs = []
            for rpc_host in self.tc_fs0_oss_pair0:
                ost_instance_config = {}
                ost_instance_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
                disk_id = self.tc_fs0_ost_disk_id_prefix + str(ost_index)
                device = DEV_MAPPER_PREFIX + disk_id
                block_device = DEV_MAPPER_PREFIX + disk_id
                if is_ldiskfs:
                    device = block_device
                else:
                    zpool = disk_id
                    device = zpool + ("/ost%d" % ost_index)
                ost_instance_config[cstr.CSTR_DEVICE] = device
                ost_instance_config[cstr.CSTR_NID] = rpc_host.lrh_ipv4_addresses[0] + "@tcp"
                ost_instance_configs.append(ost_instance_config)
                if not is_ldiskfs:
                    zpool_create = ("zpool create -f %s %s" %
                                    (zpool, block_device))
                    ost_instance_config[cstr.CSTR_ZPOOL_CREATE] = zpool_create
            ost_config[cstr.CSTR_INSTANCES] = ost_instance_configs
            ost_configs.append(ost_config)
        lustre_config[cstr.CSTR_OSTS] = ost_configs

    def _tc_generate_clownfish_config_fs0_clients(self, lustre_config):
        """
        Generate the clients part of a lustre file system of clownfish.conf
        """
        clients_configs = []
        clients_config = {}
        clients_config[cstr.CSTR_HOST_ID] = self.tc_client_host0.lrh_hostname
        clients_config[cstr.CSTR_MNT] = self.tc_fs0_mnt
        clients_configs.append(clients_config)

        clients_config = {}
        clients_config[cstr.CSTR_HOST_ID] = self.tc_client_host1.lrh_hostname
        clients_config[cstr.CSTR_MNT] = self.tc_fs0_mnt
        clients_configs.append(clients_config)
        lustre_config[cstr.CSTR_CLIENTS] = clients_configs

    def _tc_generate_clownfish_config_fs1_mdts(self, lustre_config):
        """
        Generate the mdts part of lustre 1 of clownfish.conf
        """
        mdt_configs = []
        for mdt_index in range(self.tc_fs1_mdt_number_per_mds):
            mdt_config = {}
            mdt_config[cstr.CSTR_IS_MGS] = False
            mdt_config[cstr.CSTR_INDEX] = mdt_index
            if mdt_index == self.tc_fs1_mdt_number_per_mds - 1:
                is_ldiskfs = False
            else:
                is_ldiskfs = True
            if is_ldiskfs:
                mdt_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_LDISKFS
            else:
                mdt_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_ZFS
            mdt_instance_configs = []
            for rpc_host in self.tc_fs1_mds_pair0:
                mdt_instance_config = {}
                mdt_instance_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
                disk_id = self.tc_fs1_mdt_disk_id_prefix + str(mdt_index)
                block_device = DEV_MAPPER_PREFIX + disk_id
                if is_ldiskfs:
                    device = block_device
                else:
                    zpool = disk_id
                    device = zpool + ("/mdt%d" % mdt_index)
                mdt_instance_config[cstr.CSTR_DEVICE] = device
                mdt_instance_config[cstr.CSTR_NID] = rpc_host.lrh_ipv4_addresses[0] + "@tcp"
                mdt_instance_configs.append(mdt_instance_config)
                if not is_ldiskfs:
                    zpool_create = ("zpool create -f %s %s" %
                                    (zpool, block_device))
                    mdt_instance_config[cstr.CSTR_ZPOOL_CREATE] = zpool_create
            mdt_config[cstr.CSTR_INSTANCES] = mdt_instance_configs
            mdt_configs.append(mdt_config)
        lustre_config[cstr.CSTR_MDTS] = mdt_configs

    def _tc_generate_clownfish_config_fs1_osts(self, lustre_config):
        """
        Generate the osts part of lustre 1 of clownfish.conf
        """
        ost_configs = []
        for ost_index in range(self.tc_fs1_ost_number_per_oss):
            ost_config = {}
            ost_config[cstr.CSTR_IS_MGS] = False
            ost_config[cstr.CSTR_INDEX] = ost_index
            if ost_index == self.tc_fs1_ost_number_per_oss - 1:
                is_ldiskfs = False
            else:
                is_ldiskfs = True
            if is_ldiskfs:
                ost_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_LDISKFS
            else:
                ost_config[cstr.CSTR_BACKFSTYPE] = lustre.BACKFSTYPE_ZFS
            ost_instance_configs = []
            for rpc_host in self.tc_fs1_oss_pair0:
                ost_instance_config = {}
                ost_instance_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
                disk_id = self.tc_fs1_ost_disk_id_prefix + str(ost_index)
                block_device = DEV_MAPPER_PREFIX + disk_id
                if is_ldiskfs:
                    device = block_device
                else:
                    zpool = disk_id
                    device = zpool + ("/ost%d" % ost_index)
                ost_instance_config[cstr.CSTR_DEVICE] = device
                ost_instance_config[cstr.CSTR_NID] = rpc_host.lrh_ipv4_addresses[0] + "@tcp"
                ost_instance_configs.append(ost_instance_config)
                if not is_ldiskfs:
                    zpool_create = ("zpool create -f %s %s" %
                                    (zpool, block_device))
                    ost_instance_config[cstr.CSTR_ZPOOL_CREATE] = zpool_create
            ost_config[cstr.CSTR_INSTANCES] = ost_instance_configs
            ost_configs.append(ost_config)
        lustre_config[cstr.CSTR_OSTS] = ost_configs

    def _tc_generate_clownfish_config_fs1_clients(self, lustre_config):
        """
        Generate the clients part of a lustre file system of clownfish.conf
        """
        clients_configs = []
        clients_config = {}
        clients_config[cstr.CSTR_HOST_ID] = self.tc_client_host0.lrh_hostname
        clients_config[cstr.CSTR_MNT] = self.tc_fs1_mnt
        clients_configs.append(clients_config)

        clients_config = {}
        clients_config[cstr.CSTR_HOST_ID] = self.tc_client_host1.lrh_hostname
        clients_config[cstr.CSTR_MNT] = self.tc_fs1_mnt
        clients_configs.append(clients_config)
        lustre_config[cstr.CSTR_CLIENTS] = clients_configs

    def _tc_generate_clownfish_config_lustres(self, config):
        """
        Generate the lustres part of clownfish.conf
        """
        lustre_configs = []
        lustre_config = {}
        lustre_config[cstr.CSTR_FSNAME] = self.tc_fs0_fsname
        lustre_config[cstr.CSTR_MGS_ID] = self.tc_cluster_id
        self._tc_generate_clownfish_config_fs0_mdts(lustre_config)
        self._tc_generate_clownfish_config_fs0_osts(lustre_config)
        self._tc_generate_clownfish_config_fs0_clients(lustre_config)
        lustre_configs.append(lustre_config)

        lustre_config = {}
        lustre_config[cstr.CSTR_FSNAME] = self.tc_fs1_fsname
        lustre_config[cstr.CSTR_MGS_ID] = self.tc_cluster_id
        self._tc_generate_clownfish_config_fs1_mdts(lustre_config)
        self._tc_generate_clownfish_config_fs1_osts(lustre_config)
        self._tc_generate_clownfish_config_fs1_clients(lustre_config)
        lustre_configs.append(lustre_config)
        config[cstr.CSTR_LUSTRES] = lustre_configs

    def tc_generate_clownfish_config(self, log):
        """
        Generate clownfish.conf
        """
        config = {}
        config[cstr.CSTR_LAZY_PREPARE] = True
        config[cstr.CSTR_HIGH_AVAILABILITY] = False
        config[cstr.CSTR_CLOWNFISH_PORT] = constants.CLOWNFISH_DEFAULT_SERVER_PORT
        self._tc_generate_clownfish_config_lustre_distributions(config)
        self._tc_generate_clownfish_config_ssh_hosts(config)
        self._tc_generate_clownfish_config_mgs_list(config)
        self._tc_generate_clownfish_config_lustres(config)

        config_fpath = self.tc_clownfish_config_fpath
        start_string = """#
# Configuration file of Clownfish
#
"""
        ret = self.tc_write_and_send_config(log, config, config_fpath,
                                            start_string)
        if ret:
            log.cl_error("failed to write and send clownfish.conf")
            return -1

        log.cl_info("config of clownfish.conf is saved to [%s]", config_fpath)
        return 0

    def _tc_generate_clownfish_install_config_ssh_hosts(self, config):
        """
        Generate the ssh_hosts and cluster part of clownfish.conf
        """
        ssh_host_configs = []
        cluster_host_configs = []
        for rpc_host in [self.tc_clownfish_server0, self.tc_clownfish_server1]:
            ssh_host_config = {}
            ssh_host_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
            ssh_host_config[cstr.CSTR_HOSTNAME] = rpc_host.lrh_hostname
            ssh_host_configs.append(ssh_host_config)
            cluster_host_config = {}
            cluster_host_config[cstr.CSTR_HOST_ID] = rpc_host.lrh_hostname
            cluster_host_configs.append(cluster_host_config)
        config[cstr.CSTR_SSH_HOSTS] = ssh_host_configs
        config[cstr.CSTR_CLUSTER] = cluster_host_configs

    def tc_generate_clownfish_install_config(self, log, launch_argument):
        """
        Generate clownfish_install.conf
        """
        config = {}
        rpc_ip_address = self.tc_rpc_ip_address
        config[cstr.CSTR_VIRTUAL_IP] = rpc_ip_address.ripa_address
        config[cstr.CSTR_BINDNETADDR] = rpc_ip_address.ripa_bindnetaddr
        config[cstr.CSTR_ISO_PATH] = launch_argument.la_test_host_iso_fpath
        config[cstr.CSTR_CONFIG_FPATH] = self.tc_clownfish_config_fpath
        self._tc_generate_clownfish_install_config_ssh_hosts(config)

        config_fpath = self.tc_clownfish_install_config_fpath
        start_string = """#
# Configuration file for installing Clownfish
#
"""
        ret = self.tc_write_and_send_config(log, config, config_fpath,
                                            start_string)
        if ret:
            log.cl_error("failed to write and send clownfish_test.conf")
            return -1
        log.cl_info("config of clownfish_install.conf is saved to [%s]",
                    config_fpath)
        return 0

    def tc_generate_clownfish_test_config(self, log):
        """
        Generate clownfish_test.conf
        """
        config = {}
        config[cstr.CSTR_INSTALL_CONFIG] = self.tc_clownfish_install_config_fpath
        install_server_config = {}
        install_server_config[cstr.CSTR_HOSTNAME] = self.tc_install_server.lrh_hostname
        config[cstr.CSTR_INSTALL_SERVER] = install_server_config

        config[cstr.CSTR_SKIP_INSTALL] = False
        config[cstr.CSTR_SKIP_VIRT] = False
        config[cstr.CSTR_VIRT_CONFIG] = self.tc_lvirt_config_fpath

        config_fpath = self.tc_clownfish_test_config_fpath
        start_string = """#
# Configuration file for testing Clownfish
#
"""
        ret = self.tc_write_and_send_config(log, config, config_fpath,
                                            start_string)
        if ret:
            log.cl_error("failed to write and send clownfish_test.conf")
            return -1
        log.cl_info("config of clownfish_test.conf is saved to [%s]", config_fpath)
        return 0

    def tc_generate_lvirt_config(self, log, shared_disk_dict):
        """
        Generate the config that can be digested by lvirt command
        """
        kvm_server_dict = self.tc_kvm_server_dict
        hosts = self.tc_hosts
        pairs = self.tc_pairs
        config = {}
        generate_lvirt_config_shared_disks(shared_disk_dict, config)
        generate_lvirt_config_templates(log, kvm_server_dict, config)
        generate_lvirt_config_ssh_hosts(log, hosts, pairs, config)
        generate_lvirt_config_vm_hosts(log, hosts, pairs, config)

        config_fpath = self.tc_lvirt_config_fpath
        start_string = """#
# Configuration file of installing virtual machines, used by lvirt command
#
"""
        ret = self.tc_write_and_send_config(log, config, config_fpath,
                                            start_string)
        if ret:
            log.cl_error("failed to write and send lvirt.conf")
            return -1

        log.cl_info("config of lvirt.conf is saved to [%s]", config_fpath)
        return 0

    def tc_write_and_send_config(self, log, config, config_fpath,
                                 start_string):
        """
        Write the config and send to test host
        """
        config_string = start_string
        config_string += yaml.dump(config, Dumper=lyaml.YamlDumper,
                                   default_flow_style=False)

        try:
            with open(config_fpath, 'w') as yaml_file:
                yaml_file.write(config_string)
        except:
            sys.stdout.write(config_string)
            return -1

        workspace = self.tc_workspace
        test_host = self.tc_test_host.crh_host
        ret = test_host.sh_send_file(log, config_fpath, workspace)
        if ret:
            log.cl_error("failed to send file [%s] on local host to "
                         "directory [%s] on host [%s]",
                         config_fpath, workspace, test_host.sh_hostname)
            return -1

    def tc_generate_clownfish_build_config(self, log):
        """
        Generate the config that can be digested by clownfish_build command
        """
        config = {}

        config_fpath = self.tc_clownfish_build_config_fpath
        start_string = """#
# Configuration file of building Clownfish ISO
#
"""
        ret = self.tc_write_and_send_config(log, config, config_fpath,
                                            start_string)
        if ret:
            log.cl_error("failed to write and send clownfish_build.conf")
            return -1

        log.cl_info("config of clownfish_build.conf is saved to [%s]",
                    config_fpath)
        return 0

    def tc_build_clownfish(self, log, launch_argument):
        """
        Send the clownfish source codes to remote host and build it, get the ISO back
        """
        workspace = self.tc_workspace
        host = self.tc_test_host.crh_host

        ret = send_clownfish_source(log, workspace, host, launch_argument)
        if ret:
            return -1

        remote_source_path = launch_argument.la_test_host_source_path
        clownfish_build_logdir = (remote_source_path + "/" +
                                  constants.CLOWNFISH_BUILD_LOG_DIR_BASENAME)
        log.cl_info("building Clownfish in directory [%s] on host [%s]",
                    remote_source_path, host.sh_hostname)
        command = ("cd %s && ./clownfish_build --logdir %s --config %s" %
                   (remote_source_path, clownfish_build_logdir,
                    self.tc_clownfish_build_config_fpath))
        stdout_file = workspace + "/" + "clownfish_build_watching.stdout"
        stderr_file = workspace + "/" + "clownfish_build_watching.stderr"
        retval = host.sh_watched_run(log, command, stdout_file, stderr_file)
        if retval.cr_exit_status != 0:
            log.cl_error("failed to run command [%s] on host [%s], "
                         "ret = [%d], stdout = [%s], stderr = [%s]",
                         command, host.sh_hostname,
                         retval.cr_exit_status, retval.cr_stdout,
                         retval.cr_stderr)
            ret = self.tc_get_and_clean_build_dir(log, launch_argument)
            if ret:
                log.cl_error("please check [%s] on host [%s] and [%s] on "
                             "local host to debug why build of clownfish failed",
                             remote_source_path, host.sh_hostname, workspace)
            return -1
        return 0

    def tc_get_and_clean_build_dir(self, log, launch_argument):
        """
        Get and clean the build dir on test host
        """
        remote_source_path = launch_argument.la_test_host_source_path
        host = self.tc_test_host.crh_host

        ret = self.tc_get_and_clean_dir(log, host, remote_source_path)
        if ret:
            log.cl_error("failed to get and clean dir [%s] on host [%s], "
                         "please backup it manually for further debugging",
                         remote_source_path, host.sh_hostname)
            return -1
        return 0

    def tc_prepare_workspace(self, log):
        """
        Create the workspace
        """
        workspace = self.tc_workspace
        build_host = self.tc_test_host.crh_host

        command = ("mkdir -p %s" % (workspace))
        retval = build_host.sh_run(log, command)
        if retval.cr_exit_status != 0:
            log.cl_error("failed to run command [%s] on host [%s], "
                         "ret = [%d], stdout = [%s], stderr = [%s]",
                         command, build_host.sh_hostname,
                         retval.cr_exit_status, retval.cr_stdout,
                         retval.cr_stderr)
            return -1
        return 0

    def tc_cleanup_vm_hosts(self, log):
        """
        Cleanup the virtual machones hosts
        """
        for host in self.tc_vm_hosts:
            ret = host.crh_host.sh_rpm_find_and_uninstall(log, "grep clownfish")
            if ret:
                log.cl_error("failed to uninstall Clownfish RPMs on host "
                             "[%s]", host.crh_host.sh_hostname)
                return -1
        return 0

    def tc_run_test_without_removing_build_dir(self, log, launch_argument):
        """
        Run test without removing build dir
        """
        shared_disk_dict = {}
        ret = self.tc_add_shared_devices(log, shared_disk_dict)
        if ret:
            log.cl_error("failed to add shared devices")
            return -1

        ret = self.tc_generate_lvirt_config(log, shared_disk_dict)
        if ret:
            log.cl_error("failed to generate config of lvirt")
            return -1

        ret = self.tc_generate_clownfish_config(log)
        if ret:
            log.cl_error("failed to generate config of clownfish")
            return -1

        ret = self.tc_generate_clownfish_install_config(log, launch_argument)
        if ret:
            log.cl_error("failed to generate config of installing clownfish")
            return -1

        ret = self.tc_generate_clownfish_test_config(log)
        if ret:
            log.cl_error("failed to generate config of testing clownfish")
            return -1

        ret = self.tc_run_clownfish_test(log, launch_argument)
        if ret:
            log.cl_error("failed to run Clownfish test")
            return -1

    def tc_run_test(self, log, launch_argument):
        """
        Run test on this cluster
        """
        # pylint: disable=too-many-locals,too-many-arguments,too-many-branches
        ret = self.tc_cleanup_vm_hosts(log)
        if ret:
            log.cl_error("failed to clean up VMs")
            return -1

        ret = self.tc_prepare_workspace(log)
        if ret:
            log.cl_error("failed to prepare workspace")
            return -1

        ret = self.tc_generate_clownfish_build_config(log)
        if ret:
            log.cl_error("failed to generate clownfish_build.conf")
            return -1

        ret = self.tc_build_clownfish(log, launch_argument)
        if ret:
            log.cl_error("failed to build Clownfish")
            return -1

        return_value = self.tc_run_test_without_removing_build_dir(log,
                                                                   launch_argument)
        if return_value:
            log.cl_error("failed to run tests")

        ret = self.tc_get_and_clean_build_dir(log, launch_argument)
        if ret:
            log.cl_error("failed to get and clean build directory on test host")
            return_value = -1
        return return_value


def _allocate_resources(log, scheduler_id, jobid, proxy, descs):
    """
    Allocate resources from server
    """
    rpc_descriptors = proxy.ts_resources_allocate(scheduler_id, jobid, descs)
    if len(rpc_descriptors) == 0:
        log.cl_info("not enough resources to allocate")
        return -1, None, None
    same_kvm_host_descriptors = []
    other_descriptors = []
    ltest_scheduler.rpc2descriptors(log, rpc_descriptors,
                                    same_kvm_host_descriptors,
                                    other_descriptors)
    return 0, same_kvm_host_descriptors, other_descriptors


def allocate_resources(log, scheduler_id, jobid, proxy, descs,
                       timeout=DEFAULT_HOST_TIMEOUT,
                       sleep_interval=HOST_ALLOCATION_INTERVAL):
    """
    Allocate resources from server, wait if necessary
    """
    # pylint: disable=too-many-arguments,unused-variable
    return utils.wait_condition(log, _allocate_resources,
                                (scheduler_id, jobid, proxy, descs),
                                timeout=timeout,
                                sleep_interval=sleep_interval)


def allocate_hosts_and_ip(log, scheduler_id, jobid, proxy):
    """
    Allocate hosts and IP
    """
    # pylint: disable=unused-variable
    descs = []
    des = ltest_scheduler.ResourceDescriptorIPAddress()
    descs.append(des)
    desc = ltest_scheduler.ResourceDescriptorHost(ltest_scheduler.PURPOSE_BUILD)
    descs.append(desc)
    desc = ltest_scheduler.ResourceDescriptorHost(ltest_scheduler.PURPOSE_TEST,
                                                  number_min=TestCluster.HOST_NUMBER,
                                                  number_max=TestCluster.HOST_NUMBER)
    descs.append(desc)
    for i in range(TestCluster.PAIR_NUMBER):
        desc = ltest_scheduler.ResourceDescriptorHost(ltest_scheduler.PURPOSE_TEST,
                                                      number_min=2, number_max=2,
                                                      same_kvm_server=True)
        descs.append(desc)

    ret, decs1, decs2 = allocate_resources(log, scheduler_id, jobid, proxy,
                                           descs)
    if ret:
        log.cl_error("failed to allocate hosts and IP")
    return ret, decs1, decs2


def resource2host(res, kvm_server_dict):
    """
    Transfer the RPCHost to ClientRPCHost
    """
    hostname = res.lrh_hostname
    kvm_template = res.lrh_kvm_template
    kvm_server_hostname = res.lrh_kvm_server_hostname
    if kvm_template is not None:
        template_hostname = kvm_template["vt_template_hostname"]
        # kvm_server_dict has keys of server hostnames, and values of
        # diction. The diction has keys of global template hostname,
        # and values of full template config
        if kvm_server_hostname not in kvm_server_dict:
            kvm_template_per_sever_dict = {}
            kvm_server_dict[kvm_server_hostname] = kvm_template_per_sever_dict
        kvm_template_per_sever_dict = kvm_server_dict[kvm_server_hostname]

        global_template_hostname = kvm_server_hostname + "_" + template_hostname
        if global_template_hostname not in kvm_template_per_sever_dict:
            kvm_template_config = {}
            # The template is an object of VirtTemplate
            kvm_template_config[cstr.CSTR_DNS] = kvm_template["vt_dns"]
            kvm_template_config[cstr.CSTR_ISO] = kvm_template["vt_iso"]
            kvm_template_config[cstr.CSTR_HOSTNAME] = global_template_hostname
            kvm_template_config[cstr.CSTR_INTERNET] = kvm_template["vt_internet"]
            kvm_template_config[cstr.CSTR_NETWORK_CONFIGS] = kvm_template["vt_network_configs"]
            kvm_template_config[cstr.CSTR_IMAGE_DIR] = kvm_template["vt_image_dir"]
            kvm_template_config[cstr.CSTR_DISTRO] = kvm_template["vt_distro"]
            kvm_template_config[cstr.CSTR_RAM_SIZE] = kvm_template["vt_ram_size"]
            kvm_template_config[cstr.CSTR_DISK_SIZES] = kvm_template["vt_disk_sizes"]
            kvm_template_config[cstr.CSTR_BUS_TYPE] = kvm_template["vt_bus_type"]
            kvm_template_config[cstr.CSTR_SERVER_HOST_ID] = kvm_server_hostname
            kvm_template_config[cstr.CSTR_REINSTALL] = False
            kvm_template_per_sever_dict[global_template_hostname] = kvm_template_config
        kvm_template_config = kvm_template_per_sever_dict[global_template_hostname]
    else:
        kvm_template_config = None
        global_template_hostname = None

    rpc_host = ClientRPCHost(hostname, global_template_hostname=global_template_hostname,
                             kvm_template_config=kvm_template_config,
                             kvm_server_hostname=kvm_server_hostname,
                             expected_distro=res.lrh_expected_distro,
                             ipv4_addresses=res.lrh_ipv4_addresses)
    return rpc_host


def resources2hosts(log, resources, kvm_server_dict):
    """
    Transfer an array of RPCHost to an array of ClientRPCHost
    """
    rpc_hosts = []
    hostnames = []
    for res in resources:
        rpc_host = resource2host(res, kvm_server_dict)
        rpc_hosts.append(rpc_host)
        hostnames.append(rpc_host.lrh_hostname)

    log.cl_info("allocated hosts %s", hostnames)
    return rpc_hosts


def descriptor2build_hosts(log, desc, build_host, kvm_server_dict):
    """
    Transfer an descriptor of build host to an object of ClientRPCHost
    """
    if build_host is not None:
        log.cl_error("allocated too many build host")
        return None
    if len(desc.rd_resources) != 1:
        log.cl_error("unexpected host number in the test resource, "
                     "expected %d, got %d", TestCluster.HOST_NUMBER,
                     len(desc.rd_resources))
        return None
    build_host = resource2host(desc.rd_resources[0], kvm_server_dict)
    log.cl_info("allocated build host %s", build_host.lrh_hostname)
    return build_host


def descriptor2pair_hosts(log, desc, pairs, kvm_server_dict):
    """
    Transfer an descriptor of a pair of hosts to an array of ClientRPCHost
    """
    if desc.rdh_purpose != ltest_scheduler.PURPOSE_TEST:
        log.cl_error("unexpected purpose, expected [%s], got [%s]",
                     ltest_scheduler.PURPOSE_TEST,
                     desc.rdh_purpose)
        return None
    if len(pairs) >= TestCluster.PAIR_NUMBER:
        log.cl_error("allocated too many pair hosts")
        return None
    if len(desc.rd_resources) != 2:
        log.cl_error("unexpected host number in a pair resource, "
                     "expected 2, got %d", len(desc.rd_resources))
        return None
    rpc_hosts = resources2hosts(log, desc.rd_resources, kvm_server_dict)
    pairs.append(rpc_hosts)
    return 0


def descriptor2single_hosts(log, desc, single_hosts, kvm_server_dict):
    """
    Transfer an descriptor of single hosts to an array of ClientRPCHost
    """
    if desc.rdh_purpose != ltest_scheduler.PURPOSE_TEST:
        log.cl_error("unexpected purpose, expected [%s], got [%s]",
                     ltest_scheduler.PURPOSE_TEST,
                     desc.rdh_purpose)
        return None
    if len(single_hosts) != 0:
        log.cl_error("allocated too many hosts")
        return None
    if len(desc.rd_resources) != TestCluster.HOST_NUMBER:
        log.cl_error("unexpected host number in the test resource, "
                     "expected %d, got %d", TestCluster.HOST_NUMBER,
                     len(desc.rd_resources))
        return None
    return resources2hosts(log, desc.rd_resources, kvm_server_dict)


def descriptions2cluster(log, workspace, descs):
    """
    Use the allocated resources to group a cluster
    """
    hosts = []
    build_host = None
    kvm_server_dict = {}
    rpc_ip_address = None
    pairs = []
    for desc in descs:
        if desc.rd_type == ltest_scheduler.RESOURCE_TYPE_IP_ADDRESS:
            if rpc_ip_address is not None:
                log.cl_error("unexpected multiple IPs")
                return None
            if len(desc.rd_resources) != 1:
                log.cl_error("unexpected IP number in a resource, expected 1, "
                             "got %d", len(desc.rd_resources))
                return None
            rpc_ip_address = desc.rd_resources[0]
            log.cl_info("got address [%s]", rpc_ip_address.ripa_address)
        elif desc.rd_type == ltest_scheduler.RESOURCE_TYPE_HOST:
            if desc.rdh_same_kvm_server:
                ret = descriptor2pair_hosts(log, desc, pairs, kvm_server_dict)
                if ret:
                    return None
            elif desc.rdh_purpose == ltest_scheduler.PURPOSE_BUILD:
                build_host = descriptor2build_hosts(log, desc, build_host,
                                                    kvm_server_dict)
                if build_host is None:
                    return None
            else:
                hosts = descriptor2single_hosts(log, desc, hosts, kvm_server_dict)
                if hosts is None:
                    return None
    return TestCluster(workspace, build_host, hosts, pairs, rpc_ip_address, kvm_server_dict)


def run_test_with_resources_allocated(log, workspace, launch_argument, descs):
    """
    Run the test with resources allocated
    """
    cluster = descriptions2cluster(log, workspace, descs)
    if cluster is None:
        log.cl_error("failed to group to a cluster from the resources")
        return -1
    return cluster.tc_run_test(log, launch_argument)


def run_test_connected(log, workspace, launch_argument, scheduler_id, jobid, proxy):
    """
    Run the test with connection to scheduler
    """
    # pylint: disable=too-many-arguments
    ret, descs1, descs2 = allocate_hosts_and_ip(log, scheduler_id, jobid,
                                                proxy)
    if ret:
        log.cl_error("failed to allocate hosts and IP")
        return -1

    descs = descs1 + descs2

    retval = run_test_with_resources_allocated(log, workspace, launch_argument,
                                               descs)

    ret = proxy.ts_resources_release(scheduler_id, jobid, descs)
    if ret:
        log.cl_error("failed to release hosts and IPs")
        return -1
    return retval


def send_heartbeat(log, proxy, scheduler_id, jobid):
    """
    Send heartbeat to scheduler
    Improvement: the main thread should send heatbeat and check time
    from time to time in case the heatbeat thread is broken
    """
    # pylint: disable=global-statement,broad-except
    global CHECK_TIME, EXIT_REASON, SHUTTING_DOWN
    ret = 0

    log.cl_debug("sending heartbeat")
    now = time_util.utcnow()
    try:
        ret = proxy.ts_job_heartbeat(scheduler_id, jobid)
        if ret == 0:
            CHECK_TIME = now
        else:
            SHUTTING_DOWN = True
            return -1
    except Exception, err:
        disconnet_time = (now - CHECK_TIME).seconds
        if disconnet_time <= ltest_scheduler.TEST_HEARTBEAT_TIMEOUT:
            extra_string = ("will time out in [%d] seconds" %
                            (ltest_scheduler.TEST_HEARTBEAT_TIMEOUT - disconnet_time))
        else:
            extra_string = ("already time out")
        log.cl_error("failed to send heartbeat of job [%s], "
                     "%s: %s, %s",
                     jobid, extra_string, str(err), traceback.format_exc())
        ret = -1
    disconnet_time = (now - CHECK_TIME).seconds
    if disconnet_time > ltest_scheduler.TEST_HEARTBEAT_TIMEOUT:
        EXIT_REASON = ("heatbeat of job [%s] time out, shutting down" % jobid)
        SHUTTING_DOWN = True
        return -1
    if ret:
        log.cl_error("failed to send heartbeat")
    else:
        log.cl_debug("sent heartbeat")
    return ret


def heartbeat_thread(log, proxy, scheduler_id, jobid):
    """
    Thread that send heatbeat
    """
    while True:
        time.sleep(ltest_scheduler.TEST_HEARTBEAT_INTERVAL)
        send_heartbeat(log, proxy, scheduler_id, jobid)


def run_test(log, workspace, launch_argument):
    """
    Run the test
    """
    log.cl_info("connecting to server [%s]", launch_argument.la_server)
    proxy = xmlrpclib.ServerProxy(launch_argument.la_server, allow_none=True)
    scheduler_id = proxy.ts_get_id()
    jobid = proxy.ts_job_start(scheduler_id)
    log.cl_info("got job ID [%s]", jobid)

    utils.thread_start(heartbeat_thread, (log, proxy, scheduler_id, jobid))

    ret = run_test_connected(log, workspace, launch_argument, scheduler_id,
                             jobid, proxy)

    proxy.ts_job_stop(scheduler_id, jobid)
    log.cl_info("released job [%s]", jobid)
    return ret


def parse_options(log):
    """
    Parse the options
    """
    # pylint: disable=too-many-branches
    launch_argument = LaunchArg()
    options, arguments = getopt.getopt(sys.argv[1:],
                                       "e:hl:p:s:",
                                       ["e2fsprogs",
                                        "help",
                                        "host_timeout=",
                                        "lustre="
                                        "source_path=",
                                        "server="])

    for opt, arg in options:
        if opt == "--e2fsprogs" or opt == "-e":
            ret = launch_argument.la_update_e2fsprogs_dir(log, arg)
            if ret:
                log.cl_error("invalid e2fsprogs path option [%s %s]", opt, arg)
                sys.exit(1)
        elif opt == "--help" or opt == "-h":
            usage()
            sys.exit(0)
        elif opt == "--host_timeout":
            ret = launch_argument.la_update_host_wait_time(log, int(arg))
            if ret:
                log.cl_error("invalid server option [%s]", arg)
                sys.exit(1)
        elif opt == "--lustre" or opt == "-l":
            ret = launch_argument.la_update_lustre_dir(log, arg)
            if ret:
                log.cl_error("invalid lustre path option [%s %s]", opt, arg)
                sys.exit(1)
        elif opt == "--server" or opt == "-s":
            ret = launch_argument.la_update_server(log, arg)
            if ret:
                log.cl_error("invalid server option [%s]", arg)
                sys.exit(1)
        elif opt == "--source_path" or opt == "-p":
            ret = launch_argument.la_update_source_path(log, arg)
            if ret:
                log.cl_error("invalid source path option [%s %s]", opt, arg)
                sys.exit(1)
        else:
            log.cl_error("unkown option [%s %s]", opt, arg)
            usage()
            sys.exit(1)

    if len(arguments) != 0:
        log.cl_error("unkown arguments %s", arguments)
        usage()
        sys.exit(1)

    ret = launch_argument.la_check_arguments(log)
    if ret:
        sys.exit(1)
    return launch_argument


def main():
    """
    Run the test
    """
    now = time_util.utcnow()
    workspace = (LTEST_LAUNCH_LOG_DIR + "/" +
                 time_util.local_strftime(now, ('%Y-%m-%d-%H_%M_%S')))
    retval = utils.run("mkdir -p %s" % workspace)
    if retval.cr_exit_status != 0:
        sys.stderr.write("failed to create directory [%s]\n" % workspace)
        sys.exit(1)

    log = clog.get_log(resultsdir=workspace)
    launch_argument = parse_options(log)

    return_value = 0
    ret = run_test(log, workspace, launch_argument)
    if ret:
        log.cl_error("failed to launch test")
        return_value = - 1
    else:
        log.cl_info("successfully launched the test")
    log.cl_info("moving the log from [%s] to [%s]", workspace,
                launch_argument.la_source_path)
    log.cl_fini()

    # No matter failure or sucess, move the workspace to source path
    command = ("mv %s %s" % (workspace, launch_argument.la_source_path))
    retval = utils.run(command)
    if retval.cr_exit_status != 0:
        utils.eprint("failed to run command [%s], "
                     "ret = [%d], stdout = [%s], stderr = [%s]" %
                     (command,
                      retval.cr_exit_status,
                      retval.cr_stdout,
                      retval.cr_stderr))
        utils.eprint("please check, backup and maybe delete directory of "
                     "[%s] on local host" %
                     (workspace))
        sys.exit(-1)
    basename = os.path.basename(workspace)
    logdir = launch_argument.la_source_path + "/" + basename
    if return_value:
        utils.eprint("please check [%s] for more log" % logdir)
    else:
        print("please check [%s] for more log" % logdir)

    sys.exit(return_value)
